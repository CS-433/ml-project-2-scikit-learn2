{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yb6Qb62omS3U",
    "outputId": "958e1751-6644-4743-f2dc-d092ab842ce2"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive (comment out on local)\n",
    "from google.colab import drive\n",
    "drive._mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gduOyMfnmXCX"
   },
   "outputs": [],
   "source": [
    "# comment out on Deepnote\n",
    "!cp '/content/drive/MyDrive/Voynich/corruptions.py' corruptions.py\n",
    "!cp '/content/drive/MyDrive/Voynich/uncertainties.py' uncertainties.py\n",
    "!cp '/content/drive/MyDrive/Voynich/validation.py' validation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XGN3y2QmiMR",
    "outputId": "9fa0b780-546c-4533-f1d8-9e977d42356f"
   },
   "outputs": [],
   "source": [
    "!pip install numpy==1.19.5\n",
    "!pip install scipy==1.7.3\n",
    "!pip install nltk==3.6.5\n",
    "!pip install gensim==4.1.2\n",
    "!pip install smart-open==5.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PB8oiSuamZjR"
   },
   "outputs": [],
   "source": [
    "# Colab\n",
    "INFERNO_IT = '/content/drive/MyDrive/Voynich/texts/Inferno_IT.txt'\n",
    "ZL = '/content/drive/MyDrive/Voynich/texts/ZL_raw.txt'\n",
    "\n",
    "# Local \n",
    "# INFERNO_IT = 'texts/Inferno_IT.txt'\n",
    "# ZL = 'texts/ZL_raw.txt'\n",
    "\n",
    "# DeepNote\n",
    "# INFERNO_IT = \"ml-project-2-scikit-learn2/texts/Inferno_IT.txt\"\n",
    "# ZL = 'ml-project-2-scikit-learn2/texts/ZL_raw.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZVOzi_4mmdVW",
    "outputId": "ba8d4e08-ddb6-45db-df1f-a55d44ffbee1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\franc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "nltk.download('punkt')\n",
    "\n",
    "import corruptions as corr\n",
    "import uncertainties as unc\n",
    "import validation as valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMDfF5ZjmmIU"
   },
   "source": [
    "## Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LLRqOz_OmnUS"
   },
   "outputs": [],
   "source": [
    "with open(ZL, 'r', encoding='latin-1') as doc:\n",
    "    voynich = doc.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "45P5Leosr5Ki"
   },
   "outputs": [],
   "source": [
    "# Remove all words with multiple ambiguities\n",
    "voynich = re.sub('[^ \\n]*\\?\\?\\?[^ \\n]*', '', voynich)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zhYLJYn3orb5",
    "outputId": "acadf327-1586-4482-a226-6eba0b027a7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fachys ykal ar ataiin shol shory [cth:oto]res y kor sholdy',\n",
       " 'sory ckhar or,y kair chtaiin shar ase cthar cthar,dan',\n",
       " 'syaiir sheky or ykaiin shod cthoary cthes daraiin sy',\n",
       " 'soiin oteey oteo[s:r],roloty cthiar,daiin okaiin or okan',\n",
       " 'sair,y chear cthaiin cphar cfhaiin',\n",
       " 'ydaraishy',\n",
       " \"odar c'y shol cphoy oydar sh s cfhoaiin shodary\",\n",
       " 'yshey shody okchoy otchol chocthy os,chy dain chor kos',\n",
       " 'daiin shos cfhol shody',\n",
       " 'dain os teody']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voynich_lines = [line for line in voynich.splitlines() if len(line) > 0]\n",
    "voynich_lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTEkMmkYojTF",
    "outputId": "12fda400-d9c5-42ad-9315-d2b554cdae71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fachys ykal ar ataiin shol shory [cth:oto]res y kor sholdy sory ckhar or,y kair chtaiin shar ase cthar cthar,dan syaiir sheky or ykaiin shod cthoary cthes daraiin sy soiin oteey oteo[s:r],roloty cthiar,daiin okaiin or okan sair,y chear cthaiin cphar cfhaiin ydaraishy',\n",
       " \"odar c'y shol cphoy oydar sh s cfhoaiin shodary yshey shody okchoy otchol chocthy os,chy dain chor kos daiin shos cfhol shody dain os teody\",\n",
       " 'ydain cphesaiin ols cphey ytain shoshy cphodal,es oksho kshoy otairin oteol okan shodain sckhey daiin shoy ckhey kodaiin cphy cphodaiils cthey sho oldain d dain oiin chol odaiin chodain chdy ok[a:o]in d?n cthy kod daiin shckhey ckeo r char shey kol chol chol kor chal sho chol shodan kshy kchy d or chodaiin sho koeam ycho tchey chekain sheo,pshol dydyd cthy dai[cto:Â]y yto shol she kodshey cphealy dar,ain dain ckhyds dchar shcthaiin okaiir chey Àchy \\x82tol cthols dlocto shok chor chey dain ckhey otol daiiin',\n",
       " 'cpho shaiin shokcheey chol tshodeesy shey pydeey chy r,o,d ??doin chol dain cthal dar shear kaiin dar shey cthar cho ?o kaiin shoaiin okol daiin far cthol daiin ctholdar ycheey okeey oky daiin okchey kokaiin o?chol k?dchy dal dcheo shody koshey cthy ok,chey keey keey,dal chtor ?eo? chol chok choty chotey dchaiin',\n",
       " 'd r g kchsy chydaiin ol o,l,tchey char cfhar,am yteey char or ochy dcho lkody okodar chody da,ckhy ckhockhy shy dksheey cthy kotchody dal dol chokeo dair dam sochey chokody',\n",
       " 'potoy shol dair cphoal dar chey tody otoaiin shoshy choky chol ctho,l,shol okal dolchey chodo lol chy cthy qo ol,choees cheol dol cthey ykol dol dolo ykol do,lchiody okolshol kol,kechy chol ky chol cthol chody chol daiin shor okol chol dol,ky dar shol dchor o,tcho dar [sh:Ñh]ody taor chotchey dal chody schody pol chodar',\n",
       " \"kydainy ypchol daiin otchal ypchaiin ckholsy dorchory chkar s shor cthy cto qotaiin cthey y chor chy ydy chaiin c'oaiidy chtod,dy cphy dals chokaiin d otochor al shodaiin chol,dan ytchaiin dan saiin dain,d dkol sor ytoldy dchol dchy cthy shor ckhy daiiny chol,dan\",\n",
       " \"kydain shaiin qoy s shol fodan yksh olsheey daiildy dls,sho kol sheey qokey ykody so chol,yky dain daiisol qo'ky cholaiin shol sheky daiin cthey keol saiin e'a'iin ychain dal chy dalor shan dan,olsaiin sheey ckhor okol chy chor cthor yor an chan saiin chety chyky sal sho ykeey chey daiin chcthy\",\n",
       " 'ytoail ios an on kooiin cheo,pchor otaiin,odain chor dair shty kcho,kchy sho shol qotcho loeees qoty chor daiin otchy chor lshy chol chody chodain chcthy daiin sho cholo cheor chodaiin',\n",
       " 'kchor shy daiiin chckom s,shey dor,chol,daiin dor chol chor chol keol chy chty daiin o,tchor chan daiin chotchey qoteeey chokeos chees chr cheaiin chokoishe chor cheol chol dolody']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voynich_paragraphs = voynich.split('\\n\\n')\n",
    "voynich_paragraphs = list(map(lambda par: par.replace('\\n', ' '), voynich_paragraphs))\n",
    "voynich_paragraphs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpfkktn3pdLQ"
   },
   "source": [
    "## Build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "o9a1cJBopwJE"
   },
   "outputs": [],
   "source": [
    "voynich_uncertainty_chars = {'ALTERNATE_CHAR': 'ž',\n",
    "                             'SINGLE_UNCERTAINTY': '?',\n",
    "                             'DOUBLE_UNCERTAINTY': '??',\n",
    "                             'MULTIPLE_UNCERTAINTY': '???',\n",
    "                             'UNCERTAIN_SPACE': ','\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xK6HzlEtp3Lq",
    "outputId": "4295cbd8-96f0-4cb9-bf31-b458cf26c33c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n', ' ', \"'\", '*', ',', ':', '?', 'I', '[', ']', 'a', 'b', 'c',\n",
       "       'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p',\n",
       "       'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', '\\x82', '\\x83',\n",
       "       '\\x84', '\\x85', '\\x86', '\\x87', '\\x88', '\\x89', '\\x8a', '\\x8b',\n",
       "       '\\x8c', '\\x91', '\\x92', '\\x93', '\\x94', '\\x95', '\\x96', '\\x97',\n",
       "       '\\x98', '\\x99', '\\x9a', '\\x9b', '\\x9c', '\\x9f', '¡', '¢', '£', '¤',\n",
       "       '¥', '¦', '§', '¨', '©', 'ª', '«', '¬', '®', '¯', '°', '±', '²',\n",
       "       '³', '´', 'µ', '¶', '·', '¸', '¹', 'º', '»', '¼', '½', '¾', '¿',\n",
       "       'À', 'Á', 'Â', 'Ã', 'Ä', 'Å', 'Ç', 'È', 'É', 'Ë', 'Ì', 'Î', 'Ï',\n",
       "       'Ð', 'Ñ', 'Ò', 'Ó', 'Ô', 'Õ', 'Ö', 'Ø', 'ð', 'ñ', 'ò', 'ó', 'ô',\n",
       "       'õ', 'ö'], dtype='<U1')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([*voynich])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1l9_vUsop66Z"
   },
   "outputs": [],
   "source": [
    "# For practicale purposes, we generate alternatives only for basic EVA characters\n",
    "# and not for rare chars.\n",
    "voynich_alphabet = string.ascii_lowercase #+ ''.join(['\\x82', '\\x83',\n",
    "    #    '\\x84', '\\x85', '\\x86', '\\x87', '\\x88', '\\x89', '\\x8a', '\\x8b',\n",
    "    #    '\\x8c', '\\x91', '\\x92', '\\x93', '\\x94', '\\x95', '\\x96', '\\x97',\n",
    "    #    '\\x98', '\\x99', '\\x9a', '\\x9b', '\\x9c', '\\x9f', '¡', '¢', '£', '¤',\n",
    "    #    '¥', '¦', '§', '¨', '©', 'ª', '«', '¬', '®', '¯', '°', '±', '²',\n",
    "    #    '³', '´', 'µ', '¶', '·', '¸', '¹', 'º', '»', '¼', '½', '¾', '¿',\n",
    "    #    'À', 'Á', 'Â', 'Ã', 'Ä', 'Å', 'Ç', 'È', 'É', 'Ë', 'Ì', 'Î', 'Ï',\n",
    "    #    'Ð', 'Ñ', 'Ò', 'Ó', 'Ô', 'Õ', 'Ö', 'Ø', 'ð', 'ñ', 'ò', 'ó', 'ô',\n",
    "    #    'õ', 'ö'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CRhQJkMLpfw8"
   },
   "outputs": [],
   "source": [
    "# Model 1, removing uncertain words\n",
    "lines_nounc = [unc.contextualize_sentence(sentence, sentence, \n",
    "                                           voynich_uncertainty_chars, voynich_alphabet,\n",
    "                                           is_voynich=True)\n",
    "                for sentence in voynich_lines]\n",
    "\n",
    "pars_nounc = [unc.contextualize_sentence(sentence, sentence, \n",
    "                                           voynich_uncertainty_chars, voynich_alphabet,\n",
    "                                           is_voynich=True)\n",
    "                for sentence in voynich_paragraphs]\n",
    "\n",
    "uncertainty_list_nounc, lines_nounc = list(zip(*lines_nounc))\n",
    "_, pars_nounc = list(zip(*pars_nounc))\n",
    "\n",
    "# Merge list of different sentences\n",
    "uncertainty_list_nounc = [item for sentence in uncertainty_list_nounc for item in sentence]\n",
    "\n",
    "# Split words\n",
    "lines_nounc_tokenized = [sentence.split(' ') for sentence in lines_nounc]\n",
    "pars_nounc_tokenized = [sentence.split(' ') for sentence in pars_nounc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0dcGbi66vsCZ"
   },
   "outputs": [],
   "source": [
    "vocab_nounc = [[word] for uncertainty in uncertainty_list_nounc for alternative\n",
    "                in uncertainty.alternatives_list for word in alternative.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GhNKE4tXv5df"
   },
   "outputs": [],
   "source": [
    "# Model 2, replacing corrupted letters\n",
    "lines_repunc = [unc.contextualize_sentence(sentence, sentence, \n",
    "                                           voynich_uncertainty_chars, voynich_alphabet,\n",
    "                                           convert_uncertainties='£', is_voynich=True)\n",
    "                for sentence in voynich_lines]\n",
    "\n",
    "pars_repunc = [unc.contextualize_sentence(sentence, sentence, \n",
    "                                          voynich_uncertainty_chars, voynich_alphabet,\n",
    "                                          convert_uncertainties='£', is_voynich=True)\n",
    "                for sentence in voynich_paragraphs]\n",
    "\n",
    "uncertainty_list_repunc, lines_repunc = list(zip(*lines_repunc))\n",
    "_, pars_repunc = list(zip(*pars_repunc))\n",
    "\n",
    "# Merge list of different sentences\n",
    "uncertainty_list_repunc = [item for sentence in uncertainty_list_repunc for item in sentence]\n",
    "\n",
    "# Split words\n",
    "lines_repunc_tokenized = [sentence.split(' ') for sentence in lines_nounc]\n",
    "pars_repunc_tokenized = [sentence.split(' ') for sentence in lines_repunc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "SxdqPaFFwphS"
   },
   "outputs": [],
   "source": [
    "vocab_repunc = [[word] for uncertainty in uncertainty_list_repunc for alternative\n",
    "                 in uncertainty.alternatives_list for word in alternative.split(' ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nneEOJESw1zF"
   },
   "source": [
    "## Creating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "dL04XhdRx1D0"
   },
   "outputs": [],
   "source": [
    "build_vocab = 1\n",
    "convert_uncertainties = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DEyidw17x8Bw"
   },
   "outputs": [],
   "source": [
    "text_lines = lines_nounc_tokenized if not convert_uncertainties \\\n",
    "        else lines_repunc_tokenized\n",
    "text_pars = pars_nounc_tokenized if not convert_uncertainties \\\n",
    "        else pars_repunc_tokenized\n",
    "uncert_list = uncertainty_list_nounc if not convert_uncertainties else uncertainty_list_repunc\n",
    "uncert_vocab = vocab_nounc if not convert_uncertainties else vocab_repunc\n",
    "\n",
    "how = 'softmax' if build_vocab else 'cosine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "FPfiWXoNwz8I"
   },
   "outputs": [],
   "source": [
    "params = {'alpha': 1,\n",
    "          'epochs': 20,\n",
    "          'max_n': 6,\n",
    "          'min_alpha': 0.05,\n",
    "          'min_count': 1,\n",
    "          'min_n': 2,\n",
    "          'negative': 20,\n",
    "          'sg': 0,\n",
    "          'vector_size': 100,\n",
    "          'window': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "1fsRvSvxy_k8"
   },
   "outputs": [],
   "source": [
    "window = params['window']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqaElllgw7mc"
   },
   "outputs": [],
   "source": [
    "model_lines = FastText(seed=42, **params)\n",
    "vocab = text_lines\n",
    "# vocab += uncert_vocab if build_vocab else []\n",
    "model_lines.build_vocab(vocab)\n",
    "model_lines.train(text_lines, total_examples=model_lines.corpus_count,\n",
    "                  epochs=model_lines.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yht_4X1vyqws"
   },
   "outputs": [],
   "source": [
    "model_pars = FastText(seed=42, **params)\n",
    "vocab = text_pars\n",
    "vocab += uncert_vocab if build_vocab else []\n",
    "model_pars.build_vocab(vocab)\n",
    "model_pars.train(text_pars, total_examples=model_pars.corpus_count,\n",
    "                  epochs=model_pars.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_lines = valid.predict_uncertainty(model_lines, window, uncert_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "name": "embeddings_voynich.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
